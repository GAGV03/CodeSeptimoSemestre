{"cells":[{"cell_type":"markdown","metadata":{"id":"UHSiMmT4amsM"},"source":["# Optimizing the Training Process\n","\n","In this notebook we'll put in practice some of the techniques used to improve the training process."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k89ntvHutRLj"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","from sklearn.tree import DecisionTreeClassifier, plot_tree\n","from sklearn.dummy import DummyClassifier\n","from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n","from sklearn.model_selection import GridSearchCV\n","from sklearn.model_selection import RandomizedSearchCV\n","from sklearn.model_selection import cross_validate\n","\n","from scipy.stats import uniform as sp_randFloat\n","from scipy.stats import randint as sp_randInt\n","\n","%matplotlib inline"]},{"cell_type":"markdown","metadata":{"id":"5n7pD4gCqR0f"},"source":["## The Data\n","\n","Once again, we'll be working with the [Breast Cancer dataset](https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original)) from the UCI ML Repository.\n","\n","As a reminder, this dataset consists of the following attributes:\n","\n","1. Sample code number: id number\n","2. Clump Thickness: 1 - 10\n","3. Uniformity of Cell Size: 1 - 10\n","4. Uniformity of Cell Shape: 1 - 10\n","5. Marginal Adhesion: 1 - 10\n","6. Single Epithelial Cell Size: 1 - 10\n","7. Bare Nuclei: 1 - 10\n","8. Bland Chromatin: 1 - 10\n","9. Normal Nucleoli: 1 - 10\n","10. Mitoses: 1 - 10\n","11. Class: (2 for benign, 4 for malignant)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":211},"executionInfo":{"elapsed":290,"status":"error","timestamp":1724466367466,"user":{"displayName":"Julio Guillermo Arriaga Blumenkron","userId":"18360755152457408573"},"user_tz":360},"id":"ET_pNV59Xh6L","outputId":"5dbd6772-ae60-4e34-98c4-29fb9364a972"},"outputs":[{"ename":"NameError","evalue":"name 'pd' is not defined","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-826fceaeaded>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'breast-cancer-wisconsin.data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#set column names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m data.columns = ['Sample Code Number','Clump Thickness','Uniformity of Cell Size',\n","\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"]}],"source":["#import data\n","data = pd.read_csv('breast-cancer-wisconsin.data', header=None)\n","\n","#set column names\n","data.columns = ['Sample Code Number','Clump Thickness','Uniformity of Cell Size',\n","                'Uniformity of Cell Shape','Marginal Adhesion','Single Epithelial Cell Size',\n","                'Bare Nuclei','Bland Chromatin','Normal Nucleoli','Mitoses','Class']\n","#view top 10 rows\n","data.head(10)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kxSrZcteX9cR"},"outputs":[],"source":["data = data.drop(['Sample Code Number'],axis=1) #Drop 1st column\n","data = data[data['Bare Nuclei'] != '?'] #Remove rows with missing data\n","data['Class'] = np.where(data['Class'] == 2, 0, 1) #Change the class representation\n","data['Class'].value_counts() #Class distribution"]},{"cell_type":"markdown","metadata":{"id":"S5ttKGUgr6xb"},"source":["## Splitting the data\n","\n","We'll start by separating the features from the labels, and creating Training/Testing sets using the ```train_test_split``` function."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sXgo8oxRYFnj"},"outputs":[],"source":["#Split data into attributes and class\n","X = data.drop(['Class'],axis=1)\n","y = data['Class']\n","\n","#perform training and test split\n","from sklearn.model_selection import train_test_split\n","X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"NgJkD0TcvyV_"},"source":["Before building a classification model, let's build a Dummy Classifier to determine the \"baseline\" performance. This answers the question — \"What would be the success rate of the model, if one were simply guessing?\" The dummy classifier we are using will simply predict the majority class."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BV-zMZu1shyu"},"outputs":[],"source":["#Dummy Classifier\n","clf = DummyClassifier(strategy= 'most_frequent').fit(X_train,y_train)\n","y_pred = clf.predict(X_test)\n","\n","#Distribution of y test\n","print('y actual : \\n' +  str(y_test.value_counts()))\n","\n","#Distribution of y predicted\n","print('y predicted : \\n' + str(pd.Series(y_pred).value_counts()))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hvp79frkYPwY"},"outputs":[],"source":["print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant'], zero_division=0))\n","\n","#Dummy Classifier Confusion matrix\n","cm = confusion_matrix(y_test,y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"j9falc54wHlp"},"source":["From the output, we can observe that there are 68 malignant and 103 benign cases in the test dataset. However, our classifier predicts all cases as benign (as it is the majority class). The accuracy of the model is 60%, but this is a case where accuracy may not be the best metric to evaluate the model since the classes are imbalanced. Precision, recall, f1-score and looking at the confusion matrix gives us a better idea of the true performance of this model."]},{"cell_type":"markdown","metadata":{"id":"iz0JINQ6tHRp"},"source":["## Testing and tuning models\n","\n","Now that we have the baseline performance, we can now start exploring ways to build a better model.\n","\n","As previously mentioned, the purpose of the train-test split is reserving a subset of the data to not be used during training. This allows us to evaluate the model's generalization performance on new unseen data.\n","However, when evaluating different settings (\"hyperparameters\") for estimators, there is still a risk of overfitting on the test set because the parameters can be tweaked until the estimator performs optimally. This way, knowledge about the test set can \"leak\" into the model and evaluation metrics no longer report on generalization performance. To solve this problem, yet another part of the dataset can be held out as a so-called \"validation set\": training proceeds on the training set, after which evaluation is done on the validation set, and when the experiment seems to be successful, final evaluation can be done on the test set.\n","\n","We can thus use the `train_test_split` function again to further the divide the datasets."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3QBK1EMRtM2f"},"outputs":[],"source":["X_train_t, X_val, y_train_t, y_val = train_test_split(X_train, y_train, train_size=0.9, random_state=42)"]},{"cell_type":"markdown","metadata":{"id":"YmtjRaNftdO-"},"source":["We can now use this train set to train our model, check performance with the validation set, and tune hyperparameters. Repeating this process until we're satisfied."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NBpjEjYQt-ax"},"outputs":[],"source":["clf = DecisionTreeClassifier()\n","clf.fit(X_train_t, y_train_t)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qhFEoknAlECr"},"outputs":[],"source":["# Test with Training Set\n","y_pred = clf.predict(X_train_t)\n","\n","print(classification_report(y_train_t, y_pred, target_names=['Benign', 'Malignant']))\n","\n","cm = confusion_matrix(y_train_t, y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2wzUK8QkmpAI"},"outputs":[],"source":["# Test with validation set\n","y_pred = clf.predict(X_val)\n","\n","print(classification_report(y_val, y_pred, target_names=['Benign', 'Malignant']))\n","\n","cm = confusion_matrix(y_val, y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"Na5CTXzeniYp"},"source":["At this moment, if we are not satisfied with the results, we can go back and adjust some of the model's hyperparameters. For instance, we could decide to limit the DT's max depth in order to fight overfitting."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TUzOnw7Rn_Jk"},"outputs":[],"source":["clf = DecisionTreeClassifier(max_depth=15)\n","clf.fit(X_train_t, y_train_t)"]},{"cell_type":"markdown","metadata":{"id":"leobgJPPoEXZ"},"source":["Retest the model..."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XQv4p4OMoJhR"},"outputs":[],"source":["# Test with Training Set\n","y_pred = clf.predict(X_train_t)\n","\n","print(classification_report(y_train_t, y_pred, target_names=['Benign', 'Malignant']))\n","\n","cm = confusion_matrix(y_train_t, y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6iaOgF_VoJhZ"},"outputs":[],"source":["# Test with validation set\n","y_pred = clf.predict(X_val)\n","\n","print(classification_report(y_val, y_pred, target_names=['Benign', 'Malignant']))\n","\n","cm = confusion_matrix(y_val,y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"9_OxNI-HojZp"},"source":["...and repeat until we are satisfied with the validation results.\n","\n","When done, we can retrain the model usign all of the original training data (train + validation) with the chosen hyperparameters."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qkDMUvz9o4ZY"},"outputs":[],"source":["clf = DecisionTreeClassifier(max_depth=15)\n","clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"53bbVVYTvv18"},"source":["Finally, we can check the optimized model's performance using the test set."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"evEdLKNsnBvh"},"outputs":[],"source":["y_pred = clf.predict(X_test)\n","\n","print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant']))\n","\n","cm = confusion_matrix(y_test,y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"Mb7OqL4K6XB-"},"source":["By fitting the Decision Tree model with our manually adjusted parameters, we have a much 'better' model than the previously established baseline. The accuracy is 94% and at the same time, the Precision is 95%. Now, let's take a look at the confusion matrix for this model: Looking at the misclassified instances, we can observe that 8 malignant cases have been classified incorrectly as benign (False negatives). Also, just 2 benign case has been classified as malignant (False positive)... or at least those were the results when I originally ran this experiment. These results might be different for you depending on the train-validation-test splits you get (which are pseudo-random). In the next section, we'll explore a technique to minimize potential bias introduced by a \"lucky\" or \"unlucky\" split."]},{"cell_type":"markdown","metadata":{"id":"DfQ2iBwBh9Ap"},"source":["## Cross-Validation\n","\n","As previously discussed validation sets ensure testing sets remain \"hidden\" from the training process, however, by partitioning the available data into three sets, we drastically reduce the number of samples which can be used for training the model, additionally the results can depend on a particular random choice for the pair of (train, validation) sets.\n","\n","A solution to this problem is a procedure called cross-validation (CV for short). A test set should still be held out for final evaluation, but the validation set is no longer needed when doing CV. In the basic approach, called k-fold CV, the training set is split into k smaller sets. Then, for each of these k \"folds\" a model is trained using $k-1$ of the folds as training data; and the resulting model is validated on the remaining part of the data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tNH2ijm5iDVv"},"outputs":[],"source":["clf = DecisionTreeClassifier(max_depth=15)\n","scores = cross_validate(clf, X_train, y_train, cv=5, scoring=['accuracy', 'precision', 'recall', 'f1'])\n","\n","print(f\"{scores['test_accuracy'].mean():0.2f} accuracy with a standard deviation of {scores['test_accuracy'].std():0.2f}\")\n","print(f\"{scores['test_precision'].mean():0.2f} precision with a standard deviation of {scores['test_precision'].std():0.2f}\")\n","print(f\"{scores['test_recall'].mean():0.2f} recall with a standard deviation of {scores['test_recall'].std():0.2f}\")\n","print(f\"{scores['test_f1'].mean():0.2f} f1 with a standard deviation of {scores['test_f1'].std():0.2f}\")"]},{"cell_type":"markdown","metadata":{"id":"rC4al4dZuMAh"},"source":["CV scores will give us a better overview of a particular model's (model + hyperparameters) performance on our data. However, we would still need to adjust hyperparamenters, train, score, repeat until satisfied. In the next section, we'll discuss how to automate this process."]},{"cell_type":"markdown","metadata":{"id":"ButJpCHlzNYb"},"source":["## Optimizing the model using GridSearch\n","\n"," Instead of manually trying various hyperparameter combinations, we can automates the process by programatically exploring a predefined range of hyperparameters systematically and exhaustively to find the combination that yields the best model performance. This technique is known as GridSearch."]},{"cell_type":"markdown","metadata":{"id":"bKog7cY2-aY1"},"source":["Before proceeding, let's take a closer look at our previous results."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MZdsA0AJbNM5"},"outputs":[],"source":["# Decision Tree Classifier\n","clf = DecisionTreeClassifier(max_depth=15).fit(X_train, y_train)\n","y_pred = clf.predict(X_test)\n","\n","# Model Evaluation metrics\n","print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant'], zero_division=1))\n","\n","# Classifier Confusion matrix\n","cm = confusion_matrix(y_test,y_pred)\n","cmd = ConfusionMatrixDisplay(cm, display_labels=clf.classes_)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"H1HNcZSlwwnf"},"source":["As previously noted, our DT misclassified 8 malignant tumors as benign, and 2 benign as malignant. For this particular problem, a false negative is more serious as a disease has been ignored, which can lead to the death of the patient. At the same time, a false positive would lead to an unnecessary treatment — incurring additional cost.\n","\n","Let's try to minimize the false negatives by using Grid Search to find the optimal parameters. Grid search can be used to improve any specific evaluation metric. The metric we need to focus on to reduce false negatives is Recall, hence we'll set the `scoring` parameter to `recall`.\n","\n","We'll also need to define which DT hyperparameters and possible values to explore. `GridSearchCV` will systematically perform k-fold cross validation for each possible hyperparameter combination. Track the average scores and identify the best model found.\n","\n","For this example, we'll search over different `criterion` (gini or entropy), `max_depth` and `max_features` combinations.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"y1eFIiBdAsjN"},"outputs":[],"source":["#Grid Search\n","clf = DecisionTreeClassifier()\n","grid_values = {'criterion':['gini', 'entropy'], 'max_depth':[10, 15, 20, 25, 30],\n","               'max_features':[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, None]}\n","grid_clf = GridSearchCV(clf, param_grid = grid_values, scoring = 'recall')\n","grid_clf.fit(X_train, y_train)"]},{"cell_type":"markdown","metadata":{"id":"qUxSzEKgB8wi"},"source":["We can now check the best combination of features (and their corresponding scores) found."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"O7lDMFcEemSd"},"outputs":[],"source":["# Obtain best parameters\n","best_parameters = grid_clf.best_params_\n","# Store parameters in a dataframe\n","pd.DataFrame.from_dict(best_parameters, orient='index', columns=['Assigned Value']).sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yRN9WxG4CTLE"},"outputs":[],"source":["# Obtain best score\n","grid_clf.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nMM_Kt0vczLj"},"outputs":[],"source":["#Predict values based on new parameters\n","y_pred = grid_clf.predict(X_test)\n","\n","# New Model Evaluation metrics\n","print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant'], zero_division=1))\n","\n","#Logistic Regression (Grid Search) Confusion matrix\n","cm = confusion_matrix(y_test, y_pred)\n","cmd = ConfusionMatrixDisplay(cm)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"zES2TJkSxbIu"},"source":["From the confusion matrix above, we can see that the number of false negatives has decresead by 2. We've successfully accomplished our goal, however keep in mind that GridSearch will be limited by our choice of hyperparametrs and values. Poor choices will generally lead to poor results."]},{"cell_type":"markdown","metadata":{"id":"6q5py-lf1QIr"},"source":["## Optimizing the model using RandomizedSearch\n","\n","Random search is very similar to grid search. However, instead of testing every combination of hyperparameters, random search only tests a certain number of combinations that are selected at random.\n","\n","At first glance, random search may seem unappealing. After all, if you can't test every hyperparameter combination, you are unlikely to find the best one. However, this approach does come with certain perks. Firstly, since random search tests fewer model architectures, it requires less time and less computation to obtain results, therefore we can increase the number of hyperparameters and possible values without getting exponentially higher computation times. So, although random search may not necessarily find the best possible combination of hyperparameters, it can provide a model that comes close to the ideal model in terms of performance while seaching in a bigger search space."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JQQ348t-Gi8a"},"outputs":[],"source":["# RandomizedSearch\n","clf = DecisionTreeClassifier()\n","rand_values = {'criterion':['gini', 'entropy'], 'splitter':['best', 'random'],\n","               'max_depth':sp_randInt(1, 50), 'min_samples_split':sp_randFloat(),\n","               'max_features':sp_randFloat()}\n","rand_clf = RandomizedSearchCV(clf, param_distributions = rand_values, n_iter=500, scoring='recall')\n","rand_clf.fit(X_train, y_train)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5sGW-mQXGsgt"},"outputs":[],"source":["# Obtain best parameters\n","best_parameters = rand_clf.best_params_\n","# Store parameters in a dataframe\n","pd.DataFrame.from_dict(best_parameters, orient='index', columns=['Assigned Value']).sort_index()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WfjijUb-Gsg4"},"outputs":[],"source":["# Obtain best score\n","rand_clf.best_score_"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-U5B-dcYgTG1"},"outputs":[],"source":["#Predict values based on new parameters\n","y_pred = rand_clf.predict(X_test)\n","\n","# New Model Evaluation metrics\n","print(classification_report(y_test, y_pred, target_names=['Benign', 'Malignant'], zero_division=1))\n","\n","#Logistic Regression (Grid Search) Confusion matrix\n","cm = confusion_matrix(y_test,y_pred)\n","cmd = ConfusionMatrixDisplay(cm)\n","cmd.plot()"]},{"cell_type":"markdown","metadata":{"id":"FkDUw8P4LLwK"},"source":["After RandomSearch, we've managed to achieve a similar result to those with GridSearch. Try increasing the number of iterations or adding extra hyperparameters to see if you can get a better result."]},{"cell_type":"markdown","metadata":{"id":"bqWf7IYHN8x8"},"source":["Finally, we can visualize the (surprisingly short) resulting Decision Tree."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JIo8AJzmhhtJ"},"outputs":[],"source":["plot_tree(rand_clf.best_estimator_, feature_names=rand_clf.feature_names_in_,\n","          class_names=['Benign', 'Malignant'], filled=True, rounded=True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"yJtkl1MhR3I2"},"source":["## Final Considerations\n","\n","`GridSearchCV` and `RandomizedSearchCV` are fundamental techniques for fine-tuning our models, however careful consideration should still be employed for the selection of features, values and scoring used during search. In this example we've chosen to focus on Recall, however this won't always be the case. When chosing a scoring metric, carefully consider the nature of the task and the data's characteristics. Refer to SciKit-Learn's guide on [Cross-Validation](https://scikit-learn.org/stable/modules/cross_validation.html) and [Metrics and scoring](https://scikit-learn.org/stable/modules/model_evaluation.html) for additional information."]}],"metadata":{"colab":{"provenance":[{"file_id":"1_EM0Wo6_esR80XsSPlyZ00mElOr9_XVs","timestamp":1724453371842}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.4"}},"nbformat":4,"nbformat_minor":0}
