{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c44e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from keras_preprocessing.text import Tokenizer  #type: ignore\n",
    "from keras.layers import Embedding, LSTM, Dense\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "import pickle\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a3011e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aea9a71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.1\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "873a72c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "file  = open('data.txt', 'r', encoding = \"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18092b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "lines=[]\n",
    "for i in file:\n",
    "    lines.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "440a3b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=\"\"\n",
    "for i in lines:\n",
    "    data = ' '.join(lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e92148c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace('\\n', '').replace('\\r', '').replace('\\ufeff', '').replace('“','').replace('”','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a01f9e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.split()\n",
    "data = ' '.join(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a342d7e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Project Gutenberg eBook of Los Raros This ebook is for the use of anyone anywhere in the United States and most other parts of the world at no cost and with almost no restrictions whatsoever. You may copy it, give it away or re-use it under the terms of the Project Gutenberg License included with this ebook or online at www.gutenberg.org. If you are not located in the United States, you will have to check the laws of the country where you are located before using this eBook. Title: Los Raros Author: Rubén Darío Illustrator: Enrique Ochoa Release date: November 1, 2015 [eBook #50365] Language: Spanish Credits: Produced by Josep Cols Canals, Chuck Greif and the Online Distributed Proofreading Team at http://www.pgdp.net (This file was produced from images generously made available by The Internet Archive/Canadian Libraries) *** START OF THE PROJECT GUTENBERG EBOOK LOS RAROS *** Produced by Josep Cols Canals, Chuck Greif and the Online Distributed Proofreading Team at http://www.pgdp.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6b7ed80",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400406"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a16f26f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d29d39ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(tokenizer, open('token.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32ef5b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data = tokenizer.texts_to_sequences([data])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1cadf611",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[29,\n",
       " 48,\n",
       " 125,\n",
       " 503,\n",
       " 33,\n",
       " 8,\n",
       " 419,\n",
       " 109,\n",
       " 503,\n",
       " 237,\n",
       " 219,\n",
       " 29,\n",
       " 457,\n",
       " 33,\n",
       " 1356,\n",
       " 3251,\n",
       " 69,\n",
       " 29,\n",
       " 420,\n",
       " 325,\n",
       " 64,\n",
       " 1357,\n",
       " 366,\n",
       " 3252,\n",
       " 33,\n",
       " 29,\n",
       " 3253,\n",
       " 421,\n",
       " 16,\n",
       " 2258,\n",
       " 64,\n",
       " 107,\n",
       " 3254,\n",
       " 16,\n",
       " 3255,\n",
       " 3256,\n",
       " 60,\n",
       " 422,\n",
       " 562,\n",
       " 423,\n",
       " 1699,\n",
       " 423,\n",
       " 3257,\n",
       " 58,\n",
       " 3258,\n",
       " 457,\n",
       " 423,\n",
       " 1145,\n",
       " 29,\n",
       " 274,\n",
       " 33,\n",
       " 29,\n",
       " 48,\n",
       " 125,\n",
       " 342,\n",
       " 2259,\n",
       " 107,\n",
       " 109,\n",
       " 503,\n",
       " 58,\n",
       " 1146,\n",
       " 421,\n",
       " 620,\n",
       " 125,\n",
       " 756,\n",
       " 275,\n",
       " 60,\n",
       " 256,\n",
       " 201,\n",
       " 984,\n",
       " 69,\n",
       " 29,\n",
       " 420,\n",
       " 325,\n",
       " 60,\n",
       " 862,\n",
       " 985,\n",
       " 50,\n",
       " 1700,\n",
       " 29,\n",
       " 678,\n",
       " 33,\n",
       " 29,\n",
       " 1701,\n",
       " 1358,\n",
       " 60,\n",
       " 256,\n",
       " 984,\n",
       " 1702,\n",
       " 1147,\n",
       " 109,\n",
       " 503,\n",
       " 5410,\n",
       " 8,\n",
       " 419,\n",
       " 5411,\n",
       " 1148,\n",
       " 1149,\n",
       " 5412,\n",
       " 1703]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_data[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de0dad49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68022"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "afb04b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index)+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9810f6ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14297"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7cc96627",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence=[]\n",
    "for i in range(10, len(sequence_data)):\n",
    "    words = sequence_data[i-10:i+1]\n",
    "    sequence.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3024f17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68012"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2f04d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence = np.array(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cd04438",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   29,    48,   125, ...,   503,   237,   219],\n",
       "       [   48,   125,   503, ...,   237,   219,    29],\n",
       "       [  125,   503,    33, ...,   219,    29,   457],\n",
       "       ...,\n",
       "       [   64,  2256,    50, ...,    50, 14296,   983],\n",
       "       [ 2256,    50, 14294, ..., 14296,   983,   894],\n",
       "       [   50, 14294,    50, ...,   983,   894,  1140]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16cd722f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=[]\n",
    "y=[]\n",
    "\n",
    "for i in sequence:\n",
    "    X.append(i[0:10])\n",
    "    y.append(i[10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ccda9f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5eaf5871",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d904adc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24748949",
   "metadata": {},
   "source": [
    "Building the LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "962e9f31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gustavogutierrez/miniconda3/envs/Ambiente-Conda/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, 100, input_length = 10))\n",
    "model.add(LSTM(1000, return_sequences = True)) #return_sequences=True asegura que la capa devolverá una secuencia de salidas para cada paso de la entrada, necesario para la siguiente LSTM.\n",
    "model.add(LSTM(1000))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(vocab_size, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d3ec6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)           │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ ?                      │   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)           │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ lstm_1 (\u001b[38;5;33mLSTM\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ ?                      │   \u001b[38;5;34m0\u001b[0m (unbuilt) │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe84900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e524c02a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 367ms/step - loss: 7.5918\n",
      "Epoch 2/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m416s\u001b[0m 391ms/step - loss: 6.9351\n",
      "Epoch 3/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m494s\u001b[0m 465ms/step - loss: 6.3954\n",
      "Epoch 4/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 458ms/step - loss: 6.1062\n",
      "Epoch 5/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m487s\u001b[0m 458ms/step - loss: 5.8045\n",
      "Epoch 6/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 454ms/step - loss: 5.5049\n",
      "Epoch 7/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m492s\u001b[0m 463ms/step - loss: 5.1918\n",
      "Epoch 8/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m491s\u001b[0m 462ms/step - loss: 4.9142\n",
      "Epoch 9/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m483s\u001b[0m 454ms/step - loss: 4.5878\n",
      "Epoch 10/10\n",
      "\u001b[1m1063/1063\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m495s\u001b[0m 466ms/step - loss: 4.2716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x169f6e570>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.001))\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5,restore_best_weights=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X, y, epochs=10, batch_size=64, callbacks=[early_stopping])  # Ajusta los epochs y batch_size según tus necesidades\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "59e43ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo_texto_Gustavo.keras\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3743c02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(seed_text, next_words, model, tokenizer, max_sequence_len=3):\n",
    "    for _ in range(next_words):\n",
    "        # Convertir el seed_text en una secuencia de enteros\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        \n",
    "        # Asegurarse de que el token_list tenga exactamente max_sequence_len palabras\n",
    "        token_list = token_list[-max_sequence_len:]\n",
    "        \n",
    "        # Rellenar o recortar la secuencia para que tenga max_sequence_len palabras\n",
    "        token_list = np.pad(token_list, (max(0, max_sequence_len - len(token_list)), 0), mode='constant')\n",
    "\n",
    "        # Predecir la próxima palabra\n",
    "        predicted_probs = model.predict(token_list.reshape(1, max_sequence_len), verbose=0)\n",
    "        predicted = np.argmax(predicted_probs, axis=-1)[0]\n",
    "        \n",
    "        # Obtener la palabra correspondiente al índice predicho\n",
    "        output_word = tokenizer.index_word[predicted]\n",
    "        \n",
    "        # Agregar la palabra al texto semilla\n",
    "        seed_text += \" \" + output_word\n",
    "\n",
    "    return seed_text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b2cc6fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Hay en estas páginas mucho entusiasmo, admiración sincera de la vida de los que se dejaron de los ojos de los cuales los prenden o el de los\n"
     ]
    }
   ],
   "source": [
    "seed_text = \"Hay en estas páginas mucho entusiasmo, admiración sincera\"\n",
    "generated_text = generate_text(seed_text, next_words=20, model=model, tokenizer=tokenizer)\n",
    "\n",
    "print()\n",
    "print(generated_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Ambiente-Conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
